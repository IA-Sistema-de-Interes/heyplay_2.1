{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "M74Gs_TjYl_B"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Winfredy/SadTalker/blob/main/quick_demo.ipynb)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kA89DV-sKS4i"
      },
      "source": [
        "Installation (around 5 mins)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/mjavadpur/SoundSketch_vidoe_lipSync.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "!pip install ffmpeg-python\n",
        "!pip install -r /content/SoundSketch_vidoe_lipSync/requirements.txt\n",
        "\n",
        "#If you want to use the DAIN model for frame patching, you need to install paddle.\n",
        "# CUDA 11.2\n",
        "!python -m pip install paddlepaddle-gpu==2.3.2.post112 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***Download Pretrained Models:***\n",
        "\n",
        "Pre-trained model（Pretrained model）\n",
        "\n",
        "The pretrained model looks like this:\n",
        "\n",
        "├──checkpoints\n",
        "\n",
        "|   ├──BFM_Fitting\n",
        "\n",
        "|   ├──DAIN_weight\n",
        "\n",
        "|   ├──hub\n",
        "\n",
        "|   ├──auido2exp_00300-model.pth\n",
        "\n",
        "|   ├──auido2pose_00140-model.pth\n",
        "\n",
        "|   ├──epoch_20.pth\n",
        "\n",
        "|   ├──facevid2vid_00189-model.pth.tar\n",
        "\n",
        "|   ├──GFPGANv1.3.pth\n",
        "\n",
        "|   ├──GPEN-BFR-512.pth\n",
        "\n",
        "|   ├──mapping_00109-model.pth.tar\n",
        "\n",
        "|   ├──ParseNet-latest.pth\n",
        "\n",
        "|   ├──RetinaFace-R50.pth\n",
        "\n",
        "|   ├──shape_predictor_68_face_landmarks.dat\n",
        "\n",
        "|   ├──wav2lip.pth\n",
        "\n",
        "Pre-trained model checkpoints download path:\n",
        "\n",
        "\n",
        "Baidu Skydisk：https://pan.baidu.com/s/15-zjk64SGQnRT9qIduTe2A Extraction code：klfv\n",
        "\n",
        "Google Drive：https://drive.google.com/file/d/1lW4mf5YNtS4MAD7ZkAauDDWp2N3_Qzs7/view?usp=sharing\n",
        "\n",
        "Quark network disk：https://pan.quark.cn/s/2a1042b1d046 Extraction code：zMBP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Download the compressed package and extract it to the project path (need to be executed when downloading Google Cloud Disk and Quark Cloud Disk)\n",
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1lW4mf5YNtS4MAD7ZkAauDDWp2N3_Qzs7'\n",
        "output = '/content/SoundSketch_vidoe_lipSync/checkpoints/checkpoints.tar.gz'\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !tar -zxvf /content/SoundSketch_vidoe_lipSync/checkpoints/checkpoints.tar.gz\n",
        "\n",
        "import tarfile\n",
        "\n",
        "def extract_tar_gz(file_path, extract_path='.'):\n",
        "    \"\"\"\n",
        "    Extracts a .tar.gz file to the specified path.\n",
        "    :param file_path: The path to the .tar.gz file.\n",
        "    :param extract_path: The path where the file will be extracted.\n",
        "    \"\"\"\n",
        "    with tarfile.open(file_path, 'r:gz') as tar:\n",
        "        tar.extractall(path=extract_path)\n",
        "\n",
        "# Example usage\n",
        "tar_gz_file = '/content/SoundSketch_vidoe_lipSync/checkpoints/checkpoints.tar.gz'\n",
        "extract_tar_gz(tar_gz_file, \"/content/SoundSketch_vidoe_lipSync/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python /content/SoundSketch_vidoe_lipSync/inference.py --driven_audio /content/SoundSketch_vidoe_lipSync/examples/driven_audio/chinese_poem1.wav \\\n",
        "                    --source_video /content/SoundSketch_vidoe_lipSync/examples/driven_video/1.mp4 \\\n",
        "                    --enhancer lip \\\n",
        "                    --use_DAIN \n",
        "             \t\t# --time_step 0.5 #(Frame insertion frequency, default 0.5, that is, 25fps—"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "db5031b3636a3f037ea48eb287fd3d023feb9033aefc2a9652a92e470fb0851b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
